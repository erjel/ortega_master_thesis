{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a80ad3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-22 13:29:39.966168: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-06-22 13:29:40.526208: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/joel/anaconda3/lib/python3.9/site-packages/cv2/../../lib64:/usr/local/cuda-11.2/lib64::/home/joel/anaconda3/lib/\n",
      "2023-06-22 13:29:40.526706: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/joel/anaconda3/lib/python3.9/site-packages/cv2/../../lib64:/usr/local/cuda-11.2/lib64::/home/joel/anaconda3/lib/\n",
      "2023-06-22 13:29:40.526711: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage.io as io\n",
    "import skimage.filters as flt\n",
    "from skimage.metrics import structural_similarity as SSIM\n",
    "%matplotlib inline\n",
    "# since we can't use imports\n",
    "import numpy as np\n",
    "import scipy.ndimage.filters as flt\n",
    "import warnings\n",
    "import cv2\n",
    "from glob import glob \n",
    "\n",
    "import pylab as pl\n",
    "from time import sleep\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "from matplotlib import cm\n",
    "from matplotlib.colors import ListedColormap\n",
    "import matplotlib as mpl\n",
    "import pandas as pd\n",
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "\n",
    "import sys\n",
    "sys.path.append('../../scripts')\n",
    "import open_frame\n",
    "from pm_algorithm import anisodiff\n",
    "from data_augmentation import get_generators\n",
    "from architectures import get_model\n",
    "\n",
    "\n",
    "CROP = 256\n",
    "image_size = (CROP,CROP)\n",
    "typ = \"gaussian\"\n",
    "open_frame = getattr(open_frame,typ)\n",
    "size = 5\n",
    "pre_smoothing = False\n",
    "conv = True\n",
    "sigma = 0.1\n",
    "\n",
    "\n",
    "import logging\n",
    "tf.get_logger().setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "d5c4f139",
   "metadata": {},
   "outputs": [],
   "source": [
    "class losses:\n",
    "    def Linfty(y_true,y_pred):\n",
    "        error = tf.math.log(tf.math.reduce_mean(tf.exp(tf.abs(y_true-y_pred))))\n",
    "        return error\n",
    "\n",
    "    def W1infty(y_true,y_pred):\n",
    "        error = tf.math.log(tf.math.reduce_mean(tf.exp(tf.abs(y_true-y_pred))))\n",
    "\n",
    "        dx_true,dy_true = tf.image.image_gradients(y_true)\n",
    "        dx_pred,dy_pred = tf.image.image_gradients(y_pred)\n",
    "\n",
    "        error += tf.math.log(tf.math.reduce_mean(tf.exp(tf.abs(dx_true-dx_pred))))\n",
    "        error += tf.math.log(tf.math.reduce_mean(tf.exp(tf.abs(dy_true-dy_pred))))\n",
    "\n",
    "        return error\n",
    "\n",
    "    def H1(y_true,y_pred):\n",
    "        error = tf.math.reduce_mean(tf.pow(y_true-y_pred,2))\n",
    "\n",
    "        dx_true,dy_true = tf.image.image_gradients(y_true)\n",
    "        dx_pred,dy_pred = tf.image.image_gradients(y_pred)\n",
    "\n",
    "        error += tf.math.reduce_mean(tf.pow(dx_true-dx_pred,2))\n",
    "        error += tf.math.reduce_mean(tf.pow(dy_true-dy_pred,2))\n",
    "        error = tf.sqrt(error)\n",
    "\n",
    "        return error\n",
    "\n",
    "    def L2(y_true,y_pred):\n",
    "        error = tf.math.reduce_mean(tf.pow(y_true-y_pred,2))  \n",
    "\n",
    "        return error\n",
    "\n",
    "    def probability(y_true,y_pred):\n",
    "        error = -tf.image.ssim(y_true,y_pred,255)\n",
    "\n",
    "        return error\n",
    "    \n",
    "    def product(y_true,y_pred):\n",
    "        \n",
    "        return -tf.image.psnr(y_true,y_pred,255)*tf.image.ssim(y_true,y_pred,255) \n",
    "\n",
    "    def psnr(y_true,y_pred):\n",
    "        \n",
    "        return -tf.image.psnr(y_true,y_pred,255)\n",
    "    \n",
    "    def Hpsnr(y_true,y_pred):\n",
    "        \n",
    "        error = -tf.image.psnr(y_true,y_pred,255)\n",
    "        m = tf.reduce_max(tf.abs(tf.image.image_gradients(y_true)))\n",
    "        gt = tf.image.image_gradients(y_true)\n",
    "        gp = tf.image.image_gradients(y_pred)\n",
    "        error += -tf.image.psnr(gt[0],gp[0],m)\n",
    "        error += -tf.image.psnr(gt[1],gp[1],m)\n",
    "        \n",
    "        return error \n",
    "    \n",
    "    def Hproduct(y_true,y_pred):\n",
    "        \n",
    "        error = -tf.image.psnr(y_true,y_pred,255)*tf.image.ssim(y_true,y_pred,255)\n",
    "        m = tf.reduce_max(tf.abs(tf.image.image_gradients(y_true)))\n",
    "        gt = tf.image.image_gradients(y_true)\n",
    "        gp = tf.image.image_gradients(y_pred)\n",
    "        gt = [tf.cast(g,tf.float32) for g in gt]\n",
    "        gp = [tf.cast(g,tf.float32) for g in gp]\n",
    "        error += -tf.image.psnr(gt[0],gp[0],m)*tf.image.ssim(gt[0],gt[1],m)\n",
    "        error += -tf.image.psnr(gt[1],gp[1],m)*tf.image.ssim(gt[1],gt[1],m)\n",
    "        \n",
    "        return error "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "16d81e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifier(inputs, option=1, num_classes=2,kernel_size=3,pool_size=3,CROP=256,latent_size=1024):\n",
    "    \n",
    "    \n",
    "    x = tf.keras.layers.Conv2D(32, kernel_size, strides=2, padding=\"same\")(inputs)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Activation(\"relu\")(x)\n",
    "\n",
    "    x = tf.keras.layers.Conv2D(64, kernel_size, padding=\"same\")(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Activation(\"relu\")(x)\n",
    "\n",
    "    previous_block_activation = x  # Set aside residual\n",
    "\n",
    "    for size in [16,32,64,128]:\n",
    "        x = tf.keras.layers.Activation(\"relu\")(x)\n",
    "        x = tf.keras.layers.SeparableConv2D(size, kernel_size, padding=\"same\")(x)\n",
    "        x = tf.keras.layers.BatchNormalization()(x)\n",
    "\n",
    "        x = tf.keras.layers.Activation(\"relu\")(x)\n",
    "        x = tf.keras.layers.SeparableConv2D(size, kernel_size, padding=\"same\")(x)\n",
    "        x = tf.keras.layers.BatchNormalization()(x)\n",
    "\n",
    "        x = tf.keras.layers.MaxPooling2D(pool_size, strides=2, padding=\"same\")(x)\n",
    "\n",
    "        # Project residual\n",
    "        residual = tf.keras.layers.Conv2D(size, 1, strides=2, padding=\"same\")(\n",
    "            previous_block_activation\n",
    "        )\n",
    "        x = tf.keras.layers.add([x, residual])  # Add back residual\n",
    "        previous_block_activation = x  # Set aside next residual\n",
    "\n",
    "    x = tf.keras.layers.SeparableConv2D(latent_size, kernel_size, padding=\"same\")(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Activation(\"relu\")(x)\n",
    "\n",
    "    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "    \n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "175fc0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class function_type:\n",
    "    def splines(y,num_classes,order):\n",
    "\n",
    "\n",
    "        b_initial = tf.keras.layers.Dense(1,activation='linear')(y)\n",
    "        b_initial = tf.keras.layers.Lambda(lambda z:tf.math.pow(z,2))(b_initial)\n",
    "\n",
    "        a = tf.keras.layers.Dense(num_classes*order,activation = 'linear')(y)\n",
    "\n",
    "        a = tf.keras.layers.Reshape((num_classes,order))(a)\n",
    "\n",
    "        b = tf.keras.layers.Lambda(lambda z:tf.multiply(np.asarray(1/num_classes,dtype=np.float32),tf.ones_like(z)))(a)\n",
    "        b = tf.pow(b,np.arange(1,order+1))\n",
    "        b = tf.keras.layers.multiply([a,b])\n",
    "\n",
    "        m = tf.linalg.LinearOperatorLowerTriangular(tf.ones(tf.shape(a)+(0,0,num_classes-1))).to_dense()\n",
    "        b = tf.keras.layers.multiply([tf.transpose(b,perm=(0,2,1)),m])\n",
    "        b = tf.keras.layers.Lambda(lambda z:tf.math.reduce_sum(z,axis=-1))(b)\n",
    "        b0 = tf.keras.layers.Lambda(lambda z:tf.expand_dims(tf.zeros_like(z[:,0]),axis=-1))(b)\n",
    "        b = tf.keras.layers.Concatenate(axis=1)([b0,b])\n",
    "        b = tf.keras.layers.Lambda(lambda z:z[:,:-1])(b)\n",
    "        b = tf.keras.layers.add((b,b_initial))\n",
    "        b = tf.expand_dims(b,axis=-1)\n",
    "\n",
    "        return a,b\n",
    "\n",
    "    def decreasing(y,num_classes,order):\n",
    "        b_initial = tf.keras.layers.Dense(1,activation='linear')(y)\n",
    "        b_initial = tf.keras.layers.Lambda(lambda z:tf.math.pow(z,2))(b_initial)\n",
    "        a = tf.keras.layers.Dense(num_classes*order,activation = 'linear')(y)\n",
    "        a = tf.keras.layers.Reshape((num_classes,order))(a)\n",
    "        a = tf.keras.layers.Lambda(lambda z:-tf.math.pow(z,2))(a)\n",
    "\n",
    "        b = tf.keras.layers.Lambda(lambda z:tf.multiply(np.asarray(1/num_classes,dtype=np.float32),tf.ones_like(z)))(a)\n",
    "        b = tf.pow(b,np.arange(1,order+1))\n",
    "        b = tf.keras.layers.multiply([a,b])\n",
    "\n",
    "        m = tf.linalg.LinearOperatorLowerTriangular(tf.ones(tf.shape(a)+(0,0,num_classes-1))).to_dense()\n",
    "        b = tf.keras.layers.multiply([tf.transpose(b,perm=(0,2,1)),m])\n",
    "        b = tf.keras.layers.Lambda(lambda z:tf.math.reduce_sum(z,axis=-1))(b)\n",
    "        b0 = tf.keras.layers.Lambda(lambda z:tf.expand_dims(tf.zeros_like(z[:,0]),axis=-1))(b)\n",
    "        b = tf.keras.layers.Concatenate(axis=1)([b0,b])\n",
    "        b = tf.keras.layers.Lambda(lambda z:z[:,:-1])(b)\n",
    "        b = tf.keras.layers.add((b,b_initial))\n",
    "        b = tf.expand_dims(b,axis=-1)\n",
    "\n",
    "        return a,b\n",
    "\n",
    "    def flux(y,num_classes,order):\n",
    "        b_initial = tf.keras.layers.Dense(1,activation='linear')(y)\n",
    "        b_initial = tf.keras.layers.Lambda(lambda z:tf.math.pow(z,2))(b_initial)\n",
    "\n",
    "        a = tf.keras.layers.Dense(num_classes*order,activation = 'linear')(y)\n",
    "        a = tf.keras.layers.Reshape((num_classes,order))(a)\n",
    "        #s0 = tf.keras.layers.Dense(1,activation='sigmoid')(y)\n",
    "        s0 = tf.keras.layers.Lambda(lambda z: 0.5*tf.ones_like(z))(b_initial)\n",
    "\n",
    "        b = tf.keras.layers.Lambda(lambda z:tf.multiply(np.asarray(1/num_classes,dtype=np.float32),tf.ones_like(z)))(a)\n",
    "        b = tf.keras.layers.multiply((b,s0))\n",
    "        b = tf.pow(b,np.arange(1,order+1))\n",
    "        b = tf.keras.layers.multiply([a,b])\n",
    "\n",
    "        m = tf.linalg.LinearOperatorLowerTriangular(tf.ones(tf.shape(a)+(0,0,num_classes-1))).to_dense()\n",
    "        b = tf.keras.layers.multiply([tf.transpose(b,perm=(0,2,1)),m])\n",
    "        b = tf.keras.layers.Lambda(lambda z:tf.math.reduce_sum(z,axis=-1))(b)\n",
    "        b0 = tf.keras.layers.Lambda(lambda z:tf.expand_dims(tf.zeros_like(z[:,0]),axis=-1))(b)\n",
    "        b = tf.keras.layers.Concatenate(axis=1)([b0,b])\n",
    "        b = tf.keras.layers.Lambda(lambda z:z[:,:-1])(b)\n",
    "        b = tf.keras.layers.add((b,b_initial))\n",
    "        b = tf.expand_dims(b,axis=-1)\n",
    "\n",
    "\n",
    "        minimum = tf.ones_like(a)/(num_classes)\n",
    "        fun = tf.keras.layers.multiply((s0,minimum,a))\n",
    "        fun = tf.keras.layers.add((fun,b))\n",
    "        coeffs = 2*(tf.cumsum(tf.ones_like(a)/(num_classes),axis=1))\n",
    "        coeffs = tf.keras.layers.multiply((coeffs,s0,a))\n",
    "        fun = tf.keras.layers.add((coeffs,fun))\n",
    "        minimum = tf.keras.layers.Lambda(lambda z:-tf.reduce_min(z[...,0],axis=-1))(fun)\n",
    "        minimum_neg = tf.keras.layers.Lambda(lambda z: tf.cast(tf.less_equal(-z,0),dtype=tf.float32))(minimum)\n",
    "        minimum = tf.keras.layers.multiply((minimum,minimum_neg))\n",
    "\n",
    "        b = tf.keras.layers.add((b,minimum))\n",
    "\n",
    "        a_pos,b_pos = a,b\n",
    "\n",
    "        b_middle = tf.keras.layers.Dense(1,activation='linear')(y)\n",
    "        b_middle = tf.keras.layers.Lambda(lambda z:tf.math.pow(z,2))(b_middle)\n",
    "\n",
    "\n",
    "        a = tf.keras.layers.Dense(num_classes*order,activation = 'linear')(y)\n",
    "        a = tf.keras.layers.Reshape((num_classes,order))(a)\n",
    "        s1 = tf.keras.layers.Lambda(lambda z: tf.ones_like(z)-z)(s0)\n",
    "\n",
    "        b = tf.keras.layers.Lambda(lambda z:tf.multiply(np.asarray(1/num_classes,dtype=np.float32),tf.ones_like(z)))(a)\n",
    "        b = tf.keras.layers.multiply((b,s1))\n",
    "        b = tf.pow(b,np.arange(1,order+1))\n",
    "        b = tf.keras.layers.multiply([a,b])\n",
    "\n",
    "        m = tf.linalg.LinearOperatorLowerTriangular(tf.ones(tf.shape(a)+(0,0,num_classes-1))).to_dense()\n",
    "        b = tf.keras.layers.multiply([tf.transpose(b,perm=(0,2,1)),m])\n",
    "        b = tf.keras.layers.Lambda(lambda z:tf.math.reduce_sum(z,axis=-1))(b)\n",
    "        b0 = tf.keras.layers.Lambda(lambda z:tf.expand_dims(tf.zeros_like(z[:,0]),axis=-1))(b)\n",
    "        b = tf.keras.layers.Concatenate(axis=1)([b0,b])\n",
    "        b = tf.keras.layers.Lambda(lambda z:z[:,:-1])(b)\n",
    "        b = tf.keras.layers.add((b,b_middle))\n",
    "        b = tf.expand_dims(b,axis=-1)\n",
    "\n",
    "\n",
    "        maximum = tf.ones_like(a)/(num_classes)\n",
    "        fun = tf.keras.layers.multiply((s1,maximum,a))\n",
    "        fun = tf.keras.layers.add((fun,b))\n",
    "        coeffs = 2*(tf.cumsum(tf.ones_like(a)/(num_classes),axis=1))\n",
    "        coeffs = tf.keras.layers.multiply((coeffs,s1))\n",
    "        coeffs = tf.keras.layers.add((coeffs,s0))\n",
    "        coeffs = tf.keras.layers.multiply((a,coeffs))\n",
    "        fun = tf.keras.layers.add((coeffs,fun))\n",
    "        maximum = tf.keras.layers.Lambda(lambda z:-tf.reduce_max(z[...,0],axis=-1))(fun)\n",
    "        maximum_neg = tf.keras.layers.Lambda(lambda z: tf.cast(tf.greater_equal(-z,0),dtype=tf.float32))(maximum)\n",
    "        maximum = tf.keras.layers.multiply((maximum,maximum_neg))\n",
    "        maximum = tf.keras.layers.Lambda(lambda z:tf.expand_dims(z,axis=-1))(maximum)\n",
    "\n",
    "        b = tf.keras.layers.add((b,maximum))\n",
    "\n",
    "        a_neg,b_neg = a,b\n",
    "\n",
    "        a = tf.keras.layers.Concatenate(axis=1)((a_pos,a_neg))\n",
    "        b = tf.keras.layers.Concatenate(axis=1)((b_pos,b_neg))\n",
    "\n",
    "        return a,b\n",
    "    \n",
    "    def fluxdecreasing(y,num_classes,order):\n",
    "        b_initial = tf.keras.layers.Dense(1,activation='linear')(y)\n",
    "        b_initial = tf.keras.layers.Lambda(lambda z:tf.math.pow(z,2))(b_initial)\n",
    "\n",
    "        a = tf.keras.layers.Dense(num_classes*order,activation = 'linear')(y)\n",
    "        a = tf.keras.layers.Reshape((num_classes,order))(a)\n",
    "        a = tf.keras.layers.Lambda(lambda z:-tf.math.pow(z,2))(a)\n",
    "        s0 = tf.keras.layers.Lambda(lambda z: 0.5*tf.ones_like(z))(b_initial)\n",
    "\n",
    "        b = tf.keras.layers.Lambda(lambda z:tf.multiply(np.asarray(1/num_classes,dtype=np.float32),tf.ones_like(z)))(a)\n",
    "        b = tf.keras.layers.multiply((b,s0))\n",
    "        b = tf.pow(b,np.arange(1,order+1))\n",
    "        b = tf.keras.layers.multiply([a,b])\n",
    "\n",
    "        m = tf.linalg.LinearOperatorLowerTriangular(tf.ones(tf.shape(a)+(0,0,num_classes-1))).to_dense()\n",
    "        b = tf.keras.layers.multiply([tf.transpose(b,perm=(0,2,1)),m])\n",
    "        b = tf.keras.layers.Lambda(lambda z:tf.math.reduce_sum(z,axis=-1))(b)\n",
    "        b0 = tf.keras.layers.Lambda(lambda z:tf.expand_dims(tf.zeros_like(z[:,0]),axis=-1))(b)\n",
    "        b = tf.keras.layers.Concatenate(axis=1)([b0,b])\n",
    "        b = tf.keras.layers.Lambda(lambda z:z[:,:-1])(b)\n",
    "        b = tf.keras.layers.add((b,b_initial))\n",
    "        b = tf.expand_dims(b,axis=-1)\n",
    "\n",
    "\n",
    "        minimum = tf.ones_like(a)/(num_classes)\n",
    "        fun = tf.keras.layers.multiply((s0,minimum,a))\n",
    "        fun = tf.keras.layers.add((fun,b))\n",
    "        coeffs = 2*(tf.cumsum(tf.ones_like(a)/(num_classes),axis=1))\n",
    "        coeffs = tf.keras.layers.multiply((coeffs,s0,a))\n",
    "        fun = tf.keras.layers.add((coeffs,fun))\n",
    "        minimum = tf.keras.layers.Lambda(lambda z:-tf.reduce_min(z[...,0],axis=-1))(fun)\n",
    "        minimum_neg = tf.keras.layers.Lambda(lambda z: tf.cast(tf.less_equal(-z,0),dtype=tf.float32))(minimum)\n",
    "        minimum = tf.keras.layers.multiply((minimum,minimum_neg))\n",
    "\n",
    "        b = tf.keras.layers.add((b,minimum))\n",
    "\n",
    "        a_pos,b_pos = a,b\n",
    "\n",
    "        b_middle = tf.keras.layers.Dense(1,activation='linear')(y)\n",
    "        b_middle = tf.keras.layers.Lambda(lambda z:tf.math.pow(z,2))(b_middle)\n",
    "\n",
    "\n",
    "        a = tf.keras.layers.Dense(num_classes*order,activation = 'linear')(y)\n",
    "        a = tf.keras.layers.Reshape((num_classes,order))(a)\n",
    "        a = tf.keras.layers.Lambda(lambda z:-tf.math.pow(z,2))(a)\n",
    "        s1 = tf.keras.layers.Lambda(lambda z: tf.ones_like(z)-z)(s0)\n",
    "\n",
    "        b = tf.keras.layers.Lambda(lambda z:tf.multiply(np.asarray(1/num_classes,dtype=np.float32),tf.ones_like(z)))(a)\n",
    "        b = tf.keras.layers.multiply((b,s1))\n",
    "        b = tf.pow(b,np.arange(1,order+1))\n",
    "        b = tf.keras.layers.multiply([a,b])\n",
    "\n",
    "        m = tf.linalg.LinearOperatorLowerTriangular(tf.ones(tf.shape(a)+(0,0,num_classes-1))).to_dense()\n",
    "        b = tf.keras.layers.multiply([tf.transpose(b,perm=(0,2,1)),m])\n",
    "        b = tf.keras.layers.Lambda(lambda z:tf.math.reduce_sum(z,axis=-1))(b)\n",
    "        b0 = tf.keras.layers.Lambda(lambda z:tf.expand_dims(tf.zeros_like(z[:,0]),axis=-1))(b)\n",
    "        b = tf.keras.layers.Concatenate(axis=1)([b0,b])\n",
    "        b = tf.keras.layers.Lambda(lambda z:z[:,:-1])(b)\n",
    "        b = tf.keras.layers.add((b,b_middle))\n",
    "        b = tf.expand_dims(b,axis=-1)\n",
    "\n",
    "\n",
    "        maximum = tf.ones_like(a)/(num_classes)\n",
    "        fun = tf.keras.layers.multiply((s1,maximum,a))\n",
    "        fun = tf.keras.layers.add((fun,b))\n",
    "        coeffs = 2*(tf.cumsum(tf.ones_like(a)/(num_classes),axis=1))\n",
    "        coeffs = tf.keras.layers.multiply((coeffs,s1))\n",
    "        coeffs = tf.keras.layers.add((coeffs,s0))\n",
    "        coeffs = tf.keras.layers.multiply((a,coeffs))\n",
    "        fun = tf.keras.layers.add((coeffs,fun))\n",
    "        maximum = tf.keras.layers.Lambda(lambda z:-tf.reduce_max(z[...,0],axis=-1))(fun)\n",
    "        maximum_neg = tf.keras.layers.Lambda(lambda z: tf.cast(tf.greater_equal(-z,0),dtype=tf.float32))(maximum)\n",
    "        maximum = tf.keras.layers.multiply((maximum,maximum_neg))\n",
    "        maximum = tf.keras.layers.Lambda(lambda z:tf.expand_dims(z,axis=-1))(maximum)\n",
    "\n",
    "        b = tf.keras.layers.add((b,maximum))\n",
    "\n",
    "        a_neg,b_neg = a,b\n",
    "\n",
    "        a = tf.keras.layers.Concatenate(axis=1)((a_pos,a_neg))\n",
    "        b = tf.keras.layers.Concatenate(axis=1)((b_pos,b_neg))\n",
    "\n",
    "        return a,b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "534dc7ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Creating the model\n",
    "\"\"\"\n",
    "def conv_block(x, n_filt, size_conv=(5,5), n_conv=3):\n",
    "    \"\"\"\n",
    "    Applies n_conv convolutions to the input with specified size and number of filters.\n",
    "    \"\"\"\n",
    "    for c in range(n_conv):\n",
    "        x = tf.keras.layers.Conv2D(n_filt, size_conv, padding=\"same\", activation=None)(x)\n",
    "        x = tf.keras.layers.BatchNormalization()(x)\n",
    "        x = tf.keras.layers.Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "def u_encoder(x, n_filt,degree=5):\n",
    "    \"\"\"\n",
    "    Applies conv_block and returnes max pooled and skip-connection.\n",
    "    \"\"\"\n",
    "    x = conv_block(x, n_filt,size_conv = (degree,degree))\n",
    "    return tf.keras.layers.MaxPool2D()(x), x\n",
    "\n",
    "def u_decoder(pooled, skipped, n_filt,degree=5):\n",
    "    \"\"\"\n",
    "    Upsamples pooled and concats with skiped.\n",
    "    \"\"\"\n",
    "    upsampled = tf.keras.layers.Convolution2DTranspose(n_filt, (degree,degree), strides=(2,2), padding='same')(pooled)\n",
    "    return conv_block(tf.keras.layers.concatenate([upsampled, skipped]), n_filt)\n",
    "    \n",
    "def making_awareness(p,q,n_filt,degree=5):\n",
    "    p = tf.keras.layers.Concatenate()([p,q])\n",
    "    p = conv_block(p,n_filt,size_conv = (degree,degree))\n",
    "    return p\n",
    "    \n",
    "def make_unet(input_shape, depth=5, output_channels=1,degree=5,nfilt=2,type_training='basic',it_lim=10):\n",
    "    skipped = []\n",
    "    inp = tf.keras.Input(input_shape,name='input')\n",
    "\n",
    "    p = inp\n",
    "    for _ in range(depth):\n",
    "        p, s = u_encoder(p, 2**(nfilt+_),degree=degree)\n",
    "        skipped.append(s)\n",
    "    p = conv_block(p, 2**(2+depth))\n",
    "    \n",
    "    if 'aware' in type_training:\n",
    "        inputs_aware = tf.keras.Input(shape=(1),name='aware')\n",
    "        size = int((input_shape[0]/(2**depth))**2)\n",
    "        aware = tf.keras.layers.Embedding(it_lim +1,size)(inputs_aware)\n",
    "        aware = tf.keras.layers.Reshape((input_shape[0]//(2**depth),input_shape[0]//(2**depth),1))(aware)\n",
    "        aware = conv_block(aware, 2**(2+depth))\n",
    "        p = making_awareness(p,aware, 2**(2+depth))\n",
    "    for _ in reversed(range(depth)):\n",
    "        p = u_decoder(p, skipped[_], 2**(nfilt+_),degree=degree)  \n",
    "        if 'aware' in type_training:\n",
    "            aware = tf.keras.layers.Convolution2DTranspose(2**(nfilt+_), (degree,degree), strides=(2,2), padding='same')(aware)\n",
    "            p = making_awareness(p,aware, 2**(nfilt+_))\n",
    "            \n",
    "    p = tf.keras.layers.Conv2D(output_channels, (1,1), activation='sigmoid')(p)\n",
    "    \n",
    "    if 'aware' in type_training:\n",
    "        return tf.keras.Model([inp,inputs_aware],p,name='differential_operator')\n",
    "    else:\n",
    "        return tf.keras.Model(inp,p,name='differential_operator')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "40624076",
   "metadata": {},
   "outputs": [],
   "source": [
    "def differential_operator(input_shape,num_filters,degree,typee,CROP=256,depth=3,nfilt=2,\n",
    "                          type_training='basic',it_lim=10):\n",
    "    \n",
    "    \n",
    "    if typee == 'unet':\n",
    "        return make_unet(input_shape,degree=2*degree+1,depth=depth,nfilt=nfilt,\n",
    "                         type_training=type_training,it_lim=it_lim)\n",
    "    \n",
    "    if typee == 'noconstraints':\n",
    "        \n",
    "        outputs = tf.keras.Input(shape=input_shape,name='input')        \n",
    "        diff_op = tf.keras.layers.Conv2D(num_filters,(2*degree+1,2*degree+1),padding='same',use_bias=False,name='diff')(outputs)\n",
    "        \n",
    "        if 'aware' in type_training:\n",
    "            depth = 3\n",
    "            size = int((input_shape[0]/(2**depth))**2)\n",
    "            inputs_aware = inputs_aware = tf.keras.Input(shape=(1),name='aware')\n",
    "            aware = tf.keras.layers.Embedding(it_lim +1,size)(inputs_aware)\n",
    "            aware = tf.keras.layers.Reshape((input_shape[0]//(2**depth),input_shape[0]//(2**depth),1))(aware)\n",
    "            aware = conv_block(aware, 2**(2+depth))\n",
    "            for _ in reversed(range(depth)):\n",
    "                aware = tf.keras.layers.Convolution2DTranspose(2**(nfilt+_), (degree,degree), strides=(2,2), padding='same')(aware)\n",
    "\n",
    "            diff_op = making_awareness(diff_op,aware, 2**(nfilt+_))\n",
    "            diff_op = tf.keras.layers.Conv2D(output_channels, (1,1), activation='sigmoid')(diff_op)\n",
    "        \n",
    "            return tf.keras.Model([outputs,inputs_aware],diff_op,name='differential_operator')\n",
    "        \n",
    "        else:\n",
    "            return tf.keras.Model(outputs,diff_op,name='differential_operator')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "6c6712f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 10\n",
    "\n",
    "gen_batch_train,gen_batch_val = get_generators(typ, var1_d=0, var1_u=75, CROP1=CROP, BATCH_SIZE=BATCH_SIZE, \n",
    "                                               N_REPEAT_FRAME1=1, known_variance=True, coco=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "0931c62f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class diffusor(tf.keras.Model):\n",
    "    \n",
    "    def __init__(self, arch,it_lim,image_size,loss,typ='gaussian',num_classes=1,order = 1,gamma=1,degree=3,\n",
    "             typee='noconstraints',known_variance=True,latent_size=1024,classifier=classifier,\n",
    "                 type_training = 'basic',nfilt=2,BATCH_SIZE=BATCH_SIZE):\n",
    "        \n",
    "        super().__init__()\n",
    "        self.it_lim = it_lim\n",
    "        self.order = order\n",
    "        self.gamma = gamma\n",
    "        self.degree = degree\n",
    "        self.typee = typee\n",
    "        self.known_variance = known_variance\n",
    "        self.loss = loss\n",
    "        self.loss_tracker = tf.keras.metrics.Mean(name=\"loss\")\n",
    "        self.type_training = type_training\n",
    "        self.BATCH_SIZE = BATCH_SIZE\n",
    "        \n",
    "        \n",
    "        CROP = image_size[0]\n",
    "        \n",
    "        \n",
    "        input_shape = image_size + (1,)   \n",
    "        inputs = tf.keras.Input(shape=input_shape,name='input')\n",
    "        if typee != 'classic':\n",
    "            num_filters = np.sum(2**np.arange(1,degree+1))\n",
    "            differential_model = differential_operator(input_shape,num_filters,degree,typee,CROP=CROP,\n",
    "                        depth=degree,nfilt=nfilt,type_training=type_training,it_lim=it_lim)\n",
    "        else:\n",
    "            \n",
    "            dS_n,dE_n = tf.keras.layers.Lambda(lambda z: tf.image.image_gradients(z))(inputs)\n",
    "            dS = tf.keras.layers.Lambda(lambda z: tf.pow(z,2))(dS_n)\n",
    "            dE = tf.keras.layers.Lambda(lambda z: tf.pow(z,2))(dE_n)\n",
    "            diff_op = tf.keras.layers.add((dS,dE))\n",
    "            differential_model = tf.keras.Model(inputs,diff_op)\n",
    "                \n",
    "        self.differential_model = differential_model\n",
    "\n",
    "        \n",
    "        x = tf.keras.layers.Lambda(lambda z:z/tf.math.reduce_std(z,axis=(1,2,3),keepdims=True))(inputs)\n",
    "        x = classifier(x, num_classes=num_classes,CROP=CROP,latent_size=latent_size)\n",
    "        y = tf.keras.layers.Flatten(name='y')(x)\n",
    "\n",
    "        if known_variance:\n",
    "            inputs_var = tf.keras.Input(shape=(1),name='var')\n",
    "            embedded = tf.keras.layers.Embedding(101,latent_size)(inputs_var)\n",
    "            embedded = tf.keras.layers.Flatten(name='embedded')(embedded)\n",
    "            y = tf.keras.layers.Lambda(lambda z:tf.multiply(z[0],z[1]))([y,embedded])\n",
    "\n",
    "        a,b = getattr(function_type,arch)(y,num_classes,order)    \n",
    "        b = tf.keras.layers.Lambda(lambda z: tf.multiply(tf.ones_like(z[0]),z[1]))([a,b])\n",
    "        if 'flux' in arch:\n",
    "            num_classes = 2*num_classes\n",
    "\n",
    "\n",
    "        partition_low = tf.constant(np.power(np.linspace(0,1,num_classes+1),1)[:-1])\n",
    "        partition_low = tf.expand_dims(tf.expand_dims(tf.expand_dims(partition_low,0),0),0)\n",
    "        partition_low = tf.cast(partition_low,tf.float32)\n",
    "        partition_up = tf.constant(np.power(np.linspace(0,1,num_classes+1),1)[1:])\n",
    "        partition_up = tf.expand_dims(tf.expand_dims(tf.expand_dims(partition_up,0),0),0)\n",
    "        partition_up = tf.cast(partition_up,tf.float32)\n",
    "        \n",
    "        self.partition_low = partition_low\n",
    "        self.partition_up = partition_up\n",
    "\n",
    "\n",
    "        ct = tf.keras.layers.Concatenate(name='coeff_spline')((b,a))\n",
    "        ct = tf.keras.layers.Lambda(lambda z: tf.expand_dims(tf.expand_dims(z,axis=1),axis=1))(ct)\n",
    "\n",
    "        if known_variance:\n",
    "            self.diffusivity = tf.keras.Model([inputs,inputs_var],ct)\n",
    "        else:\n",
    "            self.diffusivity = tf.keras.Model(inputs,ct)\n",
    "            \n",
    "        ct = tf.keras.Input(shape=(1,1,num_classes,2))\n",
    "        diff_op = tf.keras.Input(shape=input_shape)\n",
    "        outputs = tf.keras.Input(shape=input_shape)\n",
    "        ineq1 = tf.greater_equal(diff_op, self.partition_low)\n",
    "        ineq2 = tf.less_equal(diff_op, self.partition_up)\n",
    "\n",
    "        interval = tf.cast(tf.math.logical_and(ineq1,ineq2),tf.float32)\n",
    "\n",
    "        power_norm = tf.constant(np.asarray(np.arange(1,self.order+1),dtype='float32'))\n",
    "        power_norm = tf.keras.layers.Lambda(lambda z:tf.pow(z[0],z[1]))([diff_op,power_norm])\n",
    "        cte = tf.ones_like(diff_op)\n",
    "        power_norm = tf.keras.layers.Concatenate(axis=-1)((cte,power_norm))\n",
    "        power_norm = tf.keras.layers.Lambda(lambda z: tf.expand_dims(z,axis=-2))(power_norm)\n",
    "\n",
    "        spline = tf.keras.layers.multiply([ct,power_norm])\n",
    "        spline = tf.keras.layers.Lambda(lambda z:tf.math.reduce_sum(z,axis=-1))(spline)\n",
    "        spline = tf.keras.layers.multiply([spline,interval])\n",
    "\n",
    "        g = tf.keras.layers.Lambda(lambda z: tf.math.reduce_sum(z,axis=-1))(spline)\n",
    "        g = tf.expand_dims(g,axis=-1)\n",
    "\n",
    "\n",
    "        deltaS,deltaE = tf.keras.layers.Lambda(lambda z: tf.image.image_gradients(z))(outputs)\n",
    "        E = tf.keras.layers.multiply((g,deltaE))\n",
    "        S = tf.keras.layers.multiply((g,deltaS))\n",
    "\n",
    "        NS = S\n",
    "        EW = E\n",
    "        zeros_y = tf.expand_dims(tf.zeros_like(outputs)[:,1],axis=-1)\n",
    "        zeros_x = tf.expand_dims(tf.zeros_like(outputs)[:,1],axis=-3)\n",
    "        NS = tf.keras.layers.Concatenate(axis=1)([zeros_x,NS])\n",
    "        EW = tf.keras.layers.Concatenate(axis=2)([zeros_y,EW])\n",
    "        NS = tf.keras.layers.Lambda(lambda z: z[:,1:] - z[:,:-1])(NS)\n",
    "        EW = tf.keras.layers.Lambda(lambda z: z[:,:,1:] - z[:,:,:-1])(EW)\n",
    "\n",
    "        mult = tf.keras.layers.Lambda(lambda z: tf.multiply(tf.cast(self.gamma,dtype=tf.float32),z))(tf.ones_like(NS))\n",
    "\n",
    "        adding = tf.keras.layers.add([NS,EW])\n",
    "        adding = tf.keras.layers.multiply((mult,adding))\n",
    "        \n",
    "        self.diffusion = tf.keras.Model([diff_op,outputs,ct],adding)\n",
    "            \n",
    "    def call(self, inputs):\n",
    "        ct = self.diffusivity(inputs)\n",
    "\n",
    "        if self.known_variance:\n",
    "            outputs = inputs['input']\n",
    "        else:\n",
    "            outputs = inputs\n",
    "\n",
    "        for num_it in range(self.it_lim):\n",
    "            \n",
    "            if 'aware' in self.type_training:\n",
    "                stage = (self.it_lim-num_it)*tf.ones(self.BATCH_SIZE)\n",
    "                diff_op = self.differential_model([outputs,stage])\n",
    "            else:\n",
    "                diff_op = self.differential_model(outputs)\n",
    "            adding = self.diffusion([diff_op,outputs,ct])\n",
    "            outputs = tf.keras.layers.add([outputs,adding])\n",
    "            \n",
    "        return outputs\n",
    "    \n",
    "    def train_step(self, data):\n",
    "        x,y = data\n",
    "        \n",
    "        with tf.GradientTape() as tape:\n",
    "            ct = self.diffusivity(x,training =True)\n",
    "\n",
    "            if self.known_variance:\n",
    "                outputs = x['input']\n",
    "            else:\n",
    "                outputs = x\n",
    "\n",
    "            for num_it in range(self.it_lim):\n",
    "                \n",
    "                if 'aware' in self.type_training:\n",
    "                    stage = (self.it_lim-num_it)*tf.ones(self.BATCH_SIZE)\n",
    "                    diff_op = self.differential_model([outputs,stage],training=True)\n",
    "                else:\n",
    "                    diff_op = self.differential_model(outputs,training=True)\n",
    "                adding = self.diffusion([diff_op,outputs,ct],training=True)\n",
    "                \n",
    "                if 'greedy' in self.type_training:\n",
    "                    outputs = adding + tf.stop_gradient(outputs)\n",
    "                else:\n",
    "                    outputs = tf.keras.layers.add([outputs,adding])\n",
    "                \n",
    "            loss = self.loss(y, outputs)\n",
    "            \n",
    "        trainable_vars = self.trainable_variables\n",
    "        gradients = tape.gradient(loss, trainable_vars)\n",
    "        \n",
    "        self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n",
    "        \n",
    "        self.loss_tracker.update_state(loss)\n",
    "        return {\"loss\": self.loss_tracker.result()}\n",
    "    \n",
    "    def test_step(self, data):\n",
    "        \n",
    "        x,y = data\n",
    "        y_pred = self(x)\n",
    "        loss = self.loss(y,y_pred)\n",
    "        self.loss_tracker.update_state(loss)\n",
    "        return {\"loss\": self.loss_tracker.result()}\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "9da2ecce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "  2/100 [..............................] - ETA: 3:19 - loss: 452.4937   Batch 2: Invalid loss, terminating training\n",
      "100/100 [==============================] - 231s 690ms/step - loss: nan - val_loss: nan\n"
     ]
    }
   ],
   "source": [
    "lr = 1e-4\n",
    "tries = 1\n",
    "\n",
    "loss = 'L2'\n",
    "model = diffusor('splines',100,image_size,getattr(losses,loss),typee='unet',num_classes=10,\n",
    "                 type_training='greedy_aware')\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(lr/(tries+1)),loss=getattr(losses,loss))\n",
    "\n",
    "callbacks = [\n",
    "tf.keras.callbacks.TerminateOnNaN(),\n",
    "tf.keras.callbacks.EarlyStopping(\n",
    "monitor=\"val_loss\",\n",
    "min_delta=0,\n",
    "patience=13\n",
    ")\n",
    "\n",
    "\n",
    "]\n",
    "\n",
    "\n",
    "history = model.fit(\n",
    "    gen_batch_train,\n",
    "    epochs=2,\n",
    "    steps_per_epoch=100,\n",
    "    validation_data=gen_batch_val,\n",
    "    validation_steps=10,\n",
    "    shuffle=False,\n",
    "    use_multiprocessing=True,\n",
    "    callbacks=callbacks,\n",
    "    workers=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "51078c9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_86\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input (InputLayer)             [(None, 256, 256, 1  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " lambda_559 (Lambda)            (None, 256, 256, 1)  0           ['input[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_1967 (Conv2D)           (None, 128, 128, 32  320         ['lambda_559[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_2082 (Batc  (None, 128, 128, 32  128        ['conv2d_1967[0][0]']            \n",
      " hNormalization)                )                                                                 \n",
      "                                                                                                  \n",
      " activation_2082 (Activation)   (None, 128, 128, 32  0           ['batch_normalization_2082[0][0]'\n",
      "                                )                                ]                                \n",
      "                                                                                                  \n",
      " conv2d_1968 (Conv2D)           (None, 128, 128, 64  18496       ['activation_2082[0][0]']        \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_2083 (Batc  (None, 128, 128, 64  256        ['conv2d_1968[0][0]']            \n",
      " hNormalization)                )                                                                 \n",
      "                                                                                                  \n",
      " activation_2083 (Activation)   (None, 128, 128, 64  0           ['batch_normalization_2083[0][0]'\n",
      "                                )                                ]                                \n",
      "                                                                                                  \n",
      " activation_2084 (Activation)   (None, 128, 128, 64  0           ['activation_2083[0][0]']        \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " separable_conv2d_324 (Separabl  (None, 128, 128, 16  1616       ['activation_2084[0][0]']        \n",
      " eConv2D)                       )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_2084 (Batc  (None, 128, 128, 16  64         ['separable_conv2d_324[0][0]']   \n",
      " hNormalization)                )                                                                 \n",
      "                                                                                                  \n",
      " activation_2085 (Activation)   (None, 128, 128, 16  0           ['batch_normalization_2084[0][0]'\n",
      "                                )                                ]                                \n",
      "                                                                                                  \n",
      " separable_conv2d_325 (Separabl  (None, 128, 128, 16  416        ['activation_2085[0][0]']        \n",
      " eConv2D)                       )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_2085 (Batc  (None, 128, 128, 16  64         ['separable_conv2d_325[0][0]']   \n",
      " hNormalization)                )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d_334 (MaxPooling2  (None, 64, 64, 16)  0           ['batch_normalization_2085[0][0]'\n",
      " D)                                                              ]                                \n",
      "                                                                                                  \n",
      " conv2d_1969 (Conv2D)           (None, 64, 64, 16)   1040        ['activation_2083[0][0]']        \n",
      "                                                                                                  \n",
      " add_208 (Add)                  (None, 64, 64, 16)   0           ['max_pooling2d_334[0][0]',      \n",
      "                                                                  'conv2d_1969[0][0]']            \n",
      "                                                                                                  \n",
      " activation_2086 (Activation)   (None, 64, 64, 16)   0           ['add_208[0][0]']                \n",
      "                                                                                                  \n",
      " separable_conv2d_326 (Separabl  (None, 64, 64, 32)  688         ['activation_2086[0][0]']        \n",
      " eConv2D)                                                                                         \n",
      "                                                                                                  \n",
      " batch_normalization_2086 (Batc  (None, 64, 64, 32)  128         ['separable_conv2d_326[0][0]']   \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " activation_2087 (Activation)   (None, 64, 64, 32)   0           ['batch_normalization_2086[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " separable_conv2d_327 (Separabl  (None, 64, 64, 32)  1344        ['activation_2087[0][0]']        \n",
      " eConv2D)                                                                                         \n",
      "                                                                                                  \n",
      " batch_normalization_2087 (Batc  (None, 64, 64, 32)  128         ['separable_conv2d_327[0][0]']   \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " max_pooling2d_335 (MaxPooling2  (None, 32, 32, 32)  0           ['batch_normalization_2087[0][0]'\n",
      " D)                                                              ]                                \n",
      "                                                                                                  \n",
      " conv2d_1970 (Conv2D)           (None, 32, 32, 32)   544         ['add_208[0][0]']                \n",
      "                                                                                                  \n",
      " add_209 (Add)                  (None, 32, 32, 32)   0           ['max_pooling2d_335[0][0]',      \n",
      "                                                                  'conv2d_1970[0][0]']            \n",
      "                                                                                                  \n",
      " activation_2088 (Activation)   (None, 32, 32, 32)   0           ['add_209[0][0]']                \n",
      "                                                                                                  \n",
      " separable_conv2d_328 (Separabl  (None, 32, 32, 64)  2400        ['activation_2088[0][0]']        \n",
      " eConv2D)                                                                                         \n",
      "                                                                                                  \n",
      " batch_normalization_2088 (Batc  (None, 32, 32, 64)  256         ['separable_conv2d_328[0][0]']   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " activation_2089 (Activation)   (None, 32, 32, 64)   0           ['batch_normalization_2088[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " separable_conv2d_329 (Separabl  (None, 32, 32, 64)  4736        ['activation_2089[0][0]']        \n",
      " eConv2D)                                                                                         \n",
      "                                                                                                  \n",
      " batch_normalization_2089 (Batc  (None, 32, 32, 64)  256         ['separable_conv2d_329[0][0]']   \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " max_pooling2d_336 (MaxPooling2  (None, 16, 16, 64)  0           ['batch_normalization_2089[0][0]'\n",
      " D)                                                              ]                                \n",
      "                                                                                                  \n",
      " conv2d_1971 (Conv2D)           (None, 16, 16, 64)   2112        ['add_209[0][0]']                \n",
      "                                                                                                  \n",
      " add_210 (Add)                  (None, 16, 16, 64)   0           ['max_pooling2d_336[0][0]',      \n",
      "                                                                  'conv2d_1971[0][0]']            \n",
      "                                                                                                  \n",
      " activation_2090 (Activation)   (None, 16, 16, 64)   0           ['add_210[0][0]']                \n",
      "                                                                                                  \n",
      " separable_conv2d_330 (Separabl  (None, 16, 16, 128)  8896       ['activation_2090[0][0]']        \n",
      " eConv2D)                                                                                         \n",
      "                                                                                                  \n",
      " batch_normalization_2090 (Batc  (None, 16, 16, 128)  512        ['separable_conv2d_330[0][0]']   \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " activation_2091 (Activation)   (None, 16, 16, 128)  0           ['batch_normalization_2090[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " separable_conv2d_331 (Separabl  (None, 16, 16, 128)  17664      ['activation_2091[0][0]']        \n",
      " eConv2D)                                                                                         \n",
      "                                                                                                  \n",
      " batch_normalization_2091 (Batc  (None, 16, 16, 128)  512        ['separable_conv2d_331[0][0]']   \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " max_pooling2d_337 (MaxPooling2  (None, 8, 8, 128)   0           ['batch_normalization_2091[0][0]'\n",
      " D)                                                              ]                                \n",
      "                                                                                                  \n",
      " conv2d_1972 (Conv2D)           (None, 8, 8, 128)    8320        ['add_210[0][0]']                \n",
      "                                                                                                  \n",
      " add_211 (Add)                  (None, 8, 8, 128)    0           ['max_pooling2d_337[0][0]',      \n",
      "                                                                  'conv2d_1972[0][0]']            \n",
      "                                                                                                  \n",
      " separable_conv2d_332 (Separabl  (None, 8, 8, 1024)  133248      ['add_211[0][0]']                \n",
      " eConv2D)                                                                                         \n",
      "                                                                                                  \n",
      " batch_normalization_2092 (Batc  (None, 8, 8, 1024)  4096        ['separable_conv2d_332[0][0]']   \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " activation_2092 (Activation)   (None, 8, 8, 1024)   0           ['batch_normalization_2092[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " var (InputLayer)               [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " global_average_pooling2d_36 (G  (None, 1024)        0           ['activation_2092[0][0]']        \n",
      " lobalAveragePooling2D)                                                                           \n",
      "                                                                                                  \n",
      " embedding_78 (Embedding)       (None, 1, 1024)      103424      ['var[0][0]']                    \n",
      "                                                                                                  \n",
      " y (Flatten)                    (None, 1024)         0           ['global_average_pooling2d_36[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " embedded (Flatten)             (None, 1024)         0           ['embedding_78[0][0]']           \n",
      "                                                                                                  \n",
      " lambda_560 (Lambda)            (None, 1024)         0           ['y[0][0]',                      \n",
      "                                                                  'embedded[0][0]']               \n",
      "                                                                                                  \n",
      " dense_71 (Dense)               (None, 10)           10250       ['lambda_560[0][0]']             \n",
      "                                                                                                  \n",
      " reshape_74 (Reshape)           (None, 10, 1)        0           ['dense_71[0][0]']               \n",
      "                                                                                                  \n",
      " tf.compat.v1.shape_35 (TFOpLam  (3,)                0           ['reshape_74[0][0]']             \n",
      " bda)                                                                                             \n",
      "                                                                                                  \n",
      " lambda_562 (Lambda)            (None, 10, 1)        0           ['reshape_74[0][0]']             \n",
      "                                                                                                  \n",
      " tf.__operators__.add_35 (TFOpL  (3,)                0           ['tf.compat.v1.shape_35[0][0]']  \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " tf.math.pow_35 (TFOpLambda)    (None, 10, 1)        0           ['lambda_562[0][0]']             \n",
      "                                                                                                  \n",
      " tf.ones_35 (TFOpLambda)        (None, None, None)   0           ['tf.__operators__.add_35[0][0]']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " multiply_220 (Multiply)        (None, 10, 1)        0           ['reshape_74[0][0]',             \n",
      "                                                                  'tf.math.pow_35[0][0]']         \n",
      "                                                                                                  \n",
      " tf.convert_to_tensor_35 (TFOpL  (None, None, None)  0           ['tf.ones_35[0][0]']             \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_35 (TFO  (None, 1, 10)       0           ['multiply_220[0][0]']           \n",
      " pLambda)                                                                                         \n",
      "                                                                                                  \n",
      " tf.linalg.band_part_35 (TFOpLa  (None, None, None)  0           ['tf.convert_to_tensor_35[0][0]']\n",
      " mbda)                                                                                            \n",
      "                                                                                                  \n",
      " multiply_221 (Multiply)        (None, None, 10)     0           ['tf.compat.v1.transpose_35[0][0]\n",
      "                                                                 ',                               \n",
      "                                                                  'tf.linalg.band_part_35[0][0]'] \n",
      "                                                                                                  \n",
      " lambda_563 (Lambda)            (None, None)         0           ['multiply_221[0][0]']           \n",
      "                                                                                                  \n",
      " lambda_564 (Lambda)            (None, 1)            0           ['lambda_563[0][0]']             \n",
      "                                                                                                  \n",
      " concatenate_427 (Concatenate)  (None, None)         0           ['lambda_564[0][0]',             \n",
      "                                                                  'lambda_563[0][0]']             \n",
      "                                                                                                  \n",
      " dense_70 (Dense)               (None, 1)            1025        ['lambda_560[0][0]']             \n",
      "                                                                                                  \n",
      " lambda_565 (Lambda)            (None, None)         0           ['concatenate_427[0][0]']        \n",
      "                                                                                                  \n",
      " lambda_561 (Lambda)            (None, 1)            0           ['dense_70[0][0]']               \n",
      "                                                                                                  \n",
      " add_212 (Add)                  (None, None)         0           ['lambda_565[0][0]',             \n",
      "                                                                  'lambda_561[0][0]']             \n",
      "                                                                                                  \n",
      " tf.expand_dims_123 (TFOpLambda  (None, None, 1)     0           ['add_212[0][0]']                \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " lambda_566 (Lambda)            (None, 10, 1)        0           ['reshape_74[0][0]',             \n",
      "                                                                  'tf.expand_dims_123[0][0]']     \n",
      "                                                                                                  \n",
      " coeff_spline (Concatenate)     (None, 10, 2)        0           ['lambda_566[0][0]',             \n",
      "                                                                  'reshape_74[0][0]']             \n",
      "                                                                                                  \n",
      " lambda_567 (Lambda)            (None, 1, 1, 10, 2)  0           ['coeff_spline[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 322,939\n",
      "Trainable params: 319,739\n",
      "Non-trainable params: 3,200\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.diffusivity.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70298a1b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
