# master thesis

This is a repository showing the current state of my master thesis' code and although it contains the trained weights of the nn's I use,
it doesn't contain the training scripts since those give no further informations and was done in another computer. The idea behind the existence
of this repository is so anyone can pull it and start using it right away. It is a work in progress, so it is quite prone to change. 

The topic for my thesis is image reconstruction through learning functions and the idea is to corrupt the BSDS500 data set [1] with a given type of noise which could be Gaussian, Poisson, salt and pepper, blur or inpainting.
Afterwards I will use deep learning and the anisotropic diffusion equation given by

$$ \partial_t u =\text{div}(f(t,||u||)\nabla u)$$

to get rid of the added corruption.

## Corrupting the images

Due to the limited amount of available images in the BSDS500, I built a generator so I could apply data augmentation at the same time.
The generator's inputs are the type of noise I want to add, the variance, kernel size or proportion of image loss depending on the type I'm adding
and whether I want to apply vertical and horizontal flips or rotations as a data augmentation feature.

## Applying the anisotropic diffusion equation

The reason to choose anisotropic diffusion to do the reconstruction are the well-known properties of this algorithm when it comes to smooth images 
while at the same time preserve edges, meaning that in theory, we would be able to smooth out the images' peaks generated by the added noise 
and keep the information our original image had.

On the other hand, the way I'm trying to improve this algorithm is by using neural networks, usually based in a Unet arquitecture, to find
the function $f$ in the equation which would produce the best results in the denoising task.

## Examples

Since this is an ongoing project, it's difficult to keep examples updated.
Nevertheless, you can see below a plot comparing PSNR and SSIM my models achieve vs the one I got just using Perona-Malik functions and the original values the corrupted images had. In them you can see how regardless of the constraints I put on my functions, using a neural network also ended up in a better performance than the classical algorithm.


![Screenshot from 2023-03-06 15-20-18](https://user-images.githubusercontent.com/57953211/223136107-a069db1e-2b50-43a7-b665-9fb13deeb6af.png)


The figure below shows some examples of the outcomes.
![Screenshot from 2023-03-06 15-22-43](https://user-images.githubusercontent.com/57953211/223137288-69210aa9-fb04-4c1f-92e9-73758237ec7d.png)


## How to run
```
conda env create -n tracking -f environment.yml
python models_training.py 1 7776
```

## References

[1] https://www2.eecs.berkeley.edu/Research/Projects/CS/vision/bsds/
